{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB(Att+LSTM).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz7_kjCc0fgV"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jUcnTc32ImP"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras.models import Model\n",
        "from keras.layers import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKV_fIST0pXN"
      },
      "source": [
        "data=pd.read_csv('/content/drive/My Drive/dataset/IMDB Dataset 2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw3xDdNZ0rVb"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmKVr71S0tLx"
      },
      "source": [
        "def preprocess(w):\n",
        "  w=re.sub(r\"([?.!,%&^%$#@])\",r\" \",w)\n",
        "  w=re.sub(r'[\" \"]+',\" \",w)\n",
        "  w=re.sub(r\"[^a-zA-Z?.!,]+\",\" \",w)\n",
        "  w=w.strip()\n",
        "  w='<start>'+w+'<end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxSShXIQVmdN"
      },
      "source": [
        "data['sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwdAXwmr0vz1"
      },
      "source": [
        "texts=list(map(preprocess,data['review']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4IcRQ9s00Me"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-1JmTgO09SO"
      },
      "source": [
        "max_len=256\n",
        "max_words=20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de33va1V0-8z"
      },
      "source": [
        "tokenizer=Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences=tokenizer.texts_to_sequences(texts)\n",
        "word_index=tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlwVzCDY1D6q"
      },
      "source": [
        "data1=pad_sequences(sequences,maxlen=max_len,padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnERxFcI1Fdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c114157c-d8da-4415-e267-04ae832dd4bb"
      },
      "source": [
        "data1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g3Fq29p1G7k"
      },
      "source": [
        "labels=data['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz3uAl3c1JAg"
      },
      "source": [
        "labels1=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT0J8sJE1LTo"
      },
      "source": [
        "for i in labels:\n",
        "  if i=='positive':\n",
        "    j=1\n",
        "    labels1.append(j)\n",
        "  elif i=='negative':\n",
        "    j=0\n",
        "    labels1.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC28ZAik1Mw1"
      },
      "source": [
        "labels2=np.asarray([labels1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-kbOEks1O7L"
      },
      "source": [
        "labels2=labels2.reshape((50000, ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29_v667d1QCV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "860e36be-7f40-424c-d841-e4198b1edaa7"
      },
      "source": [
        "labels2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpKrWasA1RRY"
      },
      "source": [
        "train_data=data1[:40000]\n",
        "train_labels=labels2[:40000]\n",
        "val_data=data1[40000:]\n",
        "val_labels=labels2[40000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uID6jJSx1U04"
      },
      "source": [
        "datasett=tf.data.Dataset.from_tensor_slices((train_data,train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gefmDqXgYkm4"
      },
      "source": [
        "datasett3=tf.data.Dataset.from_tensor_slices((data1,labels2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBHDJkPYrOg"
      },
      "source": [
        "final_data=datasett3.batch(64).shuffle(50000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klyinMAf1XEU"
      },
      "source": [
        "datasett2=tf.data.Dataset.from_tensor_slices((val_data,val_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI80NJw91YU9"
      },
      "source": [
        "train_data11=datasett.batch(64).shuffle(40000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSbtXrg31Z7d"
      },
      "source": [
        "val_data11=datasett2.batch(64).shuffle(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOcqmbYf1bE4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "4d2ca0df-aec5-4785-ef2f-b4974c625395"
      },
      "source": [
        "next(iter(train_data11))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 256), dtype=int32, numpy=\n",
              " array([[  31,   17,  148, ...,    0,    0,    0],\n",
              "        [  31, 9533,    6, ...,    0,    0,    0],\n",
              "        [  22,  111,  235, ...,  130,  658,   24],\n",
              "        ...,\n",
              "        [  31,    1,  705, ...,    0,    0,    0],\n",
              "        [  31,   10,  432, ...,    0,    0,    0],\n",
              "        [  31,   50,    3, ...,    0,    0,    0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
              " array([0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXsMxmp21dHR"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,Flatten,Dense,LSTM\n",
        "from keras import layers\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Zyy9-I1hLC"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask=None):\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  \n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) \n",
        "  output = tf.matmul(attention_weights, v)  \n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK6CLT8O1rwK"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    assert d_model % self.num_heads == 0\n",
        "    self.depth = d_model // self.num_heads\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "  def split_heads(self, x, batch_size):\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "  def call(self, v, k, q):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    q = self.wq(q)  \n",
        "    k = self.wk(k)    \n",
        "    v = self.wv(v)    \n",
        "    q = self.split_heads(q, batch_size)  \n",
        "    k = self.split_heads(k, batch_size)  \n",
        "    v = self.split_heads(v, batch_size) \n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, None)\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) \n",
        "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  \n",
        "    output = self.dense(concat_attention)  \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgUIMxig1t9t"
      },
      "source": [
        "inputt=Input(shape=([None]),dtype='int32')\n",
        "emb=tf.keras.layers.Embedding(10000,512)(inputt)\n",
        "_,lstm,__=tf.keras.layers.LSTM(512,return_state=True)(emb)\n",
        "Out,weight = MultiHeadAttention(512, 8)(lstm,lstm,lstm)\n",
        "lstm2=tf.keras.layers.LSTM(256)(Out)\n",
        "den=tf.keras.layers.Dense(128,activation='relu')(lstm2)\n",
        "drop=tf.keras.layers.Dropout(0.8)(den)\n",
        "#max=tf.keras.layers.GlobalMaxPool1D()(drop)\n",
        "\n",
        "den2=tf.keras.layers.Dense(1,activation='sigmoid')(drop)\n",
        "model=Model(inputs=inputt,outputs=den2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vS-Kh0O1-W2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "3dcfe8af-d2d5-48d9-afb7-82d5d7f8a4f4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_21\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_12 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, None, 512)    5120000     input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_20 (LSTM)                  [(None, 512), (None, 2099200     embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_11 (MultiH ((None, None, 512),  1050624     lstm_20[0][1]                    \n",
            "                                                                 lstm_20[0][1]                    \n",
            "                                                                 lstm_20[0][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_21 (LSTM)                  (None, 256)          787456      multi_head_attention_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_70 (Dense)                (None, 128)          32896       lstm_21[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 128)          0           dense_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_71 (Dense)                (None, 1)            129         dropout_10[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 9,090,305\n",
            "Trainable params: 9,090,305\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3mjqquz_McU"
      },
      "source": [
        "b=tf.keras.layers.LSTM(256)\n",
        "dd=tf.keras.layers.Embedding(30000,256)\n",
        "d=tf.keras.layers.Dense(64)\n",
        "m=tf.keras.layers.Flatten()\n",
        "ccc=tf.keras.layers.GlobalMaxPool1D()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u-G5f0M_LxO"
      },
      "source": [
        "S_inputs = Input(shape=([None]), dtype='int32')\n",
        "embeddings = dd(S_inputs)\n",
        "\n",
        "c=b(embeddings)\n",
        "O_seq,a = MultiHeadAttention(512, 8)(c,c,c)\n",
        "b_seq=d(O_seq)\n",
        "e = Dropout(0)(b_seq)\n",
        "e=ccc(e)\n",
        "outputs = Dense(1, activation='softmax')(e)\n",
        "model1 = Model(inputs=S_inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeCvhqZx_skl"
      },
      "source": [
        "model2= tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(10000, 128),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeAjChkq7qCY"
      },
      "source": [
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCb9o6sP38eD"
      },
      "source": [
        "loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYEwTJdO4C4U"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.SGD(learning_rate=0.1), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQRQXwI2WqT4"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.9999,epsilon=None,decay=0.01,amsgrad=False), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nEerZldYy5m"
      },
      "source": [
        "hist= model.fit(final_data,epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XY57X4t4DF1"
      },
      "source": [
        "hist= model.fit(train_data11,epochs=20,validation_data=(val_data11))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3USmR5ZP4OxS"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}