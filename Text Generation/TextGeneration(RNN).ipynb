{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGeneration(RNN).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUyYEz3QiSCO"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-VjHq7vy5Nt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a044f6b5-e9f6-4f0d-db93-f948298e56a4"
      },
      "source": [
        "path_to_file=tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8jGn3OkzIkd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f49c9e9-92d2-4d18-f12a-5ac6779f9b73"
      },
      "source": [
        "path_to_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/shakespeare.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySZWXqu4zsI0"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEnIysC8zSew"
      },
      "source": [
        "text=open(path_to_file,'rb').read().decode(encoding='utf-8')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXFPS-V5zkRK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ced579a-af9b-452d-be98-dee76600821d"
      },
      "source": [
        "print('Length of text: {} characters'.format(len(text)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDL8aQLazl1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "00835d43-32d3-468d-8efe-dc877e3bbd93"
      },
      "source": [
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dx0THWszomX"
      },
      "source": [
        "vocab=sorted(set(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkC2IqPt0B-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "322e4bf1-3124-4377-c5c5-33232d8c5345"
      },
      "source": [
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '$',\n",
              " '&',\n",
              " \"'\",\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '3',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0ga9Vin0DKY"
      },
      "source": [
        "char2idx={u:i for i,u in enumerate(vocab)}\n",
        "idx2char=np.array(vocab)\n",
        "text_as_int=np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijQSz5a70Zam",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f159d448-c80e-4c2c-cc59-60eff261a6bf"
      },
      "source": [
        "len(text_as_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbDi3q_70a2U"
      },
      "source": [
        "seq_length=100\n",
        "examples_per_epoch=len(text)//(seq_length+1)\n",
        "char_dataset=tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0H0mGvG2t46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebb44419-c0df-4c2a-c0f6-bd10956e2dde"
      },
      "source": [
        "next(iter(char_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ERBw76C2vR-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f11c7b7-8177-4137-c26a-31650a3c055b"
      },
      "source": [
        "sequences=char_dataset.batch(seq_length+1,drop_remainder=True)\n",
        "for item in sequences.take(5):\n",
        "  print(len(item))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11CTwkro3Til",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "272af2cf-077c-4ea9-f1aa-6c84fd81635c"
      },
      "source": [
        "len(text_as_int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd5NrFZ-3imu"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text=chunk[:-1]\n",
        "  target_text=chunk[1:]\n",
        "  return input_text,target_text\n",
        "dataset=sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJs0LVJV3_Ok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9e3934e1-ed13-4088-ac0d-849a72a7dec2"
      },
      "source": [
        "next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              " array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,\n",
              "        44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39,\n",
              "        52, 63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1,\n",
              "        51, 43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31,\n",
              "        54, 43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56,\n",
              "        57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59])>,\n",
              " <tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
              " array([47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
              "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52,\n",
              "        63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51,\n",
              "        43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54,\n",
              "        43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57,\n",
              "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex1AtQZD4BBT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ecd702fd-2dc7-4e28-b01a-d3f33b957bfd"
      },
      "source": [
        "for input_example, target_example in  dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0eAStUv4PPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d99a66b5-8f3a-40af-db07-c5650dc6c3b6"
      },
      "source": [
        "idx2char"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
              "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
              "      dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV12Q_An4Q50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52154ee3-80fe-455f-d943-1cc6e4ad05ba"
      },
      "source": [
        "char2idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '$': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " ',': 6,\n",
              " '-': 7,\n",
              " '.': 8,\n",
              " '3': 9,\n",
              " ':': 10,\n",
              " ';': 11,\n",
              " '?': 12,\n",
              " 'A': 13,\n",
              " 'B': 14,\n",
              " 'C': 15,\n",
              " 'D': 16,\n",
              " 'E': 17,\n",
              " 'F': 18,\n",
              " 'G': 19,\n",
              " 'H': 20,\n",
              " 'I': 21,\n",
              " 'J': 22,\n",
              " 'K': 23,\n",
              " 'L': 24,\n",
              " 'M': 25,\n",
              " 'N': 26,\n",
              " 'O': 27,\n",
              " 'P': 28,\n",
              " 'Q': 29,\n",
              " 'R': 30,\n",
              " 'S': 31,\n",
              " 'T': 32,\n",
              " 'U': 33,\n",
              " 'V': 34,\n",
              " 'W': 35,\n",
              " 'X': 36,\n",
              " 'Y': 37,\n",
              " 'Z': 38,\n",
              " 'a': 39,\n",
              " 'b': 40,\n",
              " 'c': 41,\n",
              " 'd': 42,\n",
              " 'e': 43,\n",
              " 'f': 44,\n",
              " 'g': 45,\n",
              " 'h': 46,\n",
              " 'i': 47,\n",
              " 'j': 48,\n",
              " 'k': 49,\n",
              " 'l': 50,\n",
              " 'm': 51,\n",
              " 'n': 52,\n",
              " 'o': 53,\n",
              " 'p': 54,\n",
              " 'q': 55,\n",
              " 'r': 56,\n",
              " 's': 57,\n",
              " 't': 58,\n",
              " 'u': 59,\n",
              " 'v': 60,\n",
              " 'w': 61,\n",
              " 'x': 62,\n",
              " 'y': 63,\n",
              " 'z': 64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKkjpm454Toq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "16763b52-e2b4-450a-99e0-27b973989804"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print(\"Step {:4d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 18 ('F')\n",
            "  expected output: 47 ('i')\n",
            "Step    1\n",
            "  input: 47 ('i')\n",
            "  expected output: 56 ('r')\n",
            "Step    2\n",
            "  input: 56 ('r')\n",
            "  expected output: 57 ('s')\n",
            "Step    3\n",
            "  input: 57 ('s')\n",
            "  expected output: 58 ('t')\n",
            "Step    4\n",
            "  input: 58 ('t')\n",
            "  expected output: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-BnWYrI4XZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d144d9-3873-4e25-9b73-d538540b7dfc"
      },
      "source": [
        "BATCH_SIZE=64\n",
        "BUFFER_SIZE=10000\n",
        "dataset=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfO_F7vx4tXB"
      },
      "source": [
        "vocab_size=len(vocab)\n",
        "embedding_dim=256\n",
        "rnn_units=1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9arzmoU426N"
      },
      "source": [
        "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
        "  model=tf.keras.Sequential([\n",
        "      tf.keras.layers.Embedding(vocab_size,embedding_dim,batch_input_shape=[batch_size,None]),\n",
        "      tf.keras.layers.GRU(rnn_units,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'),\n",
        "      tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x19OfNq76BdZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1bdc1864-a274-4e75-a30f-65ed6a6dbf36"
      },
      "source": [
        "next(iter(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 100), dtype=int64, numpy=\n",
              " array([[60, 43, 56, ..., 63, 53, 59],\n",
              "        [56,  1, 50, ...,  1, 40, 59],\n",
              "        [47, 50, 50, ..., 15, 23, 21],\n",
              "        ...,\n",
              "        [58, 46, 43, ..., 46, 39, 58],\n",
              "        [ 6,  1, 53, ...,  1, 41, 53],\n",
              "        [ 0, 21,  1, ..., 21, 33, 31]])>,\n",
              " <tf.Tensor: shape=(64, 100), dtype=int64, numpy=\n",
              " array([[43, 56,  1, ..., 53, 59, 56],\n",
              "        [ 1, 50, 53, ..., 40, 59, 56],\n",
              "        [50, 50,  1, ..., 23, 21, 26],\n",
              "        ...,\n",
              "        [46, 43,  1, ..., 39, 58,  1],\n",
              "        [ 1, 53, 56, ..., 41, 53, 59],\n",
              "        [21,  1, 39, ..., 33, 31, 10]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg5yWJZL6FQM"
      },
      "source": [
        "model=build_model(vocab_size=len(vocab),embedding_dim=embedding_dim,rnn_units=rnn_units,batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt5XVqGh6pnc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1059393-d5ec-43e7-c9dc-35b627d9a099"
      },
      "source": [
        "for input_example_batch,target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions=model(input_example_batch)\n",
        "  print(example_batch_predictions.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9iwSuW_7vNm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7c8375bf-b54d-4e30-a533-2e1016948991"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw_Afztz7zgQ"
      },
      "source": [
        "sampled_indices=tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dppArM3P8SjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "219fce4a-f85b-4feb-a795-b930ec00c2f4"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 35, 48, 49, 39, 44, 64, 39,  8, 64, 49, 16, 50, 58, 63, 24, 41,\n",
              "       57, 45, 38, 26, 50,  8, 43, 34, 29,  4, 23,  6, 41,  8, 29, 30,  7,\n",
              "       52, 59, 28, 52, 45, 51, 51, 49, 39, 51, 56, 15, 12, 62, 10, 41, 19,\n",
              "       59, 51, 12, 31, 52, 31, 38, 32, 22, 43, 46, 41, 37, 51, 52, 28, 34,\n",
              "       49, 36, 37, 21, 38, 28,  3, 61, 34, 63,  0, 61, 52, 64, 58, 53, 28,\n",
              "       33, 16, 15, 60, 51, 40, 13, 40, 36, 54, 53, 10, 39,  7, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyxO3Xvv8USJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e4ef8aa5-d028-4fc8-ebac-07d82b326011"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " \"utinous; and it is rumour'd,\\nCominius, Marcius your old enemy,\\nWho is of Rome worse hated than of yo\"\n",
            "\n",
            "Next Char Predictions: \n",
            " 'FWjkafza.zkDltyLcsgZNl.eVQ&K,c.QR-nuPngmmkamrC?x:cGum?SnSZTJehcYmnPVkXYIZP$wVy\\nwnztoPUDCvmbAbXpo:a-T'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0DfYdVr-UUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9146d330-13a9-4d9f-f19e-472c5477d504"
      },
      "source": [
        "def loss(labels,logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)\n",
        "example_batch_loss=loss(target_example_batch,example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.1743183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXEE9DqvAsI_"
      },
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A6rIHh5A0Fd"
      },
      "source": [
        "checkpoint_dir='./training_checkpoints'\n",
        "checkpoint_prefix=os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBACHylYBo1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cf3af3db-c42b-4aa7-e3ef-19d3a81d5e79"
      },
      "source": [
        "EPOCHS=10\n",
        "history=model.fit(dataset,epochs=EPOCHS,callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 2.6462\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.9515\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.6877\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.5409\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.4540\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.3953\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.3488\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.3104\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.2767\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 1.2443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4e0BHCjDOag",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d5685cc-ca43-4759-f809-a283417d6d55"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N7XXLXUDZ9e"
      },
      "source": [
        "model=build_model(vocab_size,embedding_dim,rnn_units,batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW7whjgkE5gD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b35db6e0-5814-4902-ac49-a53eeed15bae"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 65)             66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPoee3fAGu5V"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Evaluation step (generating text using the learned model)\n",
        "\n",
        "    # Number of characters to generate\n",
        "    num_generate = 1000\n",
        "\n",
        "    # Converting our start string to numbers (vectorizing)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Empty string to store our results\n",
        "    text_generated = []\n",
        "\n",
        "    # Low temperature results in more predictable text.\n",
        "    # Higher temperature results in more surprising text.\n",
        "    # Experiment to find the best setting.\n",
        "    temperature = 1.0\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWxJRnwBHBOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "250f1c37-5b77-4951-cbcb-65840a699dc1"
      },
      "source": [
        "example_batch_predictions[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 65])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g57-QgLSJVN_"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3-KI0aiJkEa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2773184f-2b99-4741-e10d-f21ba24d9edc"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 1), dtype=int64, numpy=\n",
              "array([[62],\n",
              "       [42],\n",
              "       [12],\n",
              "       [60],\n",
              "       [24],\n",
              "       [56],\n",
              "       [38],\n",
              "       [ 1],\n",
              "       [15],\n",
              "       [51],\n",
              "       [ 7],\n",
              "       [37],\n",
              "       [ 0],\n",
              "       [32],\n",
              "       [48],\n",
              "       [46],\n",
              "       [42],\n",
              "       [48],\n",
              "       [30],\n",
              "       [38],\n",
              "       [29],\n",
              "       [30],\n",
              "       [40],\n",
              "       [47],\n",
              "       [58],\n",
              "       [57],\n",
              "       [20],\n",
              "       [58],\n",
              "       [17],\n",
              "       [37],\n",
              "       [30],\n",
              "       [21],\n",
              "       [31],\n",
              "       [20],\n",
              "       [ 7],\n",
              "       [41],\n",
              "       [24],\n",
              "       [ 1],\n",
              "       [64],\n",
              "       [51],\n",
              "       [18],\n",
              "       [15],\n",
              "       [54],\n",
              "       [55],\n",
              "       [ 1],\n",
              "       [56],\n",
              "       [ 6],\n",
              "       [ 6],\n",
              "       [20],\n",
              "       [34],\n",
              "       [26],\n",
              "       [22],\n",
              "       [22],\n",
              "       [ 2],\n",
              "       [ 9],\n",
              "       [49],\n",
              "       [60],\n",
              "       [23],\n",
              "       [ 6],\n",
              "       [15],\n",
              "       [34],\n",
              "       [15],\n",
              "       [25],\n",
              "       [10],\n",
              "       [41],\n",
              "       [49],\n",
              "       [ 8],\n",
              "       [57],\n",
              "       [ 8],\n",
              "       [15],\n",
              "       [43],\n",
              "       [37],\n",
              "       [23],\n",
              "       [47],\n",
              "       [ 4],\n",
              "       [ 6],\n",
              "       [ 1],\n",
              "       [23],\n",
              "       [13],\n",
              "       [30],\n",
              "       [17],\n",
              "       [25],\n",
              "       [48],\n",
              "       [20],\n",
              "       [16],\n",
              "       [37],\n",
              "       [62],\n",
              "       [ 1],\n",
              "       [47],\n",
              "       [46],\n",
              "       [61],\n",
              "       [ 7],\n",
              "       [48],\n",
              "       [15],\n",
              "       [64],\n",
              "       [ 2],\n",
              "       [54],\n",
              "       [31],\n",
              "       [28],\n",
              "       [ 6]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18nrnPrTJk8Y"
      },
      "source": [
        "aa=tf.argmax(example_batch_predictions[0][0],axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCyYkr8uKA6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd8c9fa4-4132-463c-a667-7189927fc0a0"
      },
      "source": [
        "aa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYCoOMHEKBrf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ea678c8-dafe-4898-d9c5-7b387727daa3"
      },
      "source": [
        "for i in example_batch_predictions[0][0]:\n",
        "  print(i)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(-0.002006608, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djwUq6CYRsBD"
      },
      "source": [
        "c=tf.argmax(example_batch_predictions[0][65])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkZx1vxgRuaI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8be03f5-293b-4e7d-9ce4-b5b43fa14ddf"
      },
      "source": [
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=24>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoOX83rVP00k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "bf83e25a-efc0-444f-a66f-a3493821c8ff"
      },
      "source": [
        "example_batch_predictions[0][65]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(65,), dtype=float32, numpy=\n",
              "array([ 0.00029799, -0.0018327 ,  0.00073117,  0.01142994, -0.00192412,\n",
              "       -0.00757303,  0.00225865, -0.01609945,  0.01143583,  0.01764401,\n",
              "       -0.01296948, -0.01150754,  0.01326837,  0.01601107, -0.00116881,\n",
              "       -0.00037472,  0.0026346 ,  0.00493955,  0.00790331,  0.00383052,\n",
              "       -0.00416242,  0.01049338,  0.01261466,  0.00793483,  0.02782   ,\n",
              "       -0.00505296, -0.01110025, -0.00125062,  0.01024919,  0.00030212,\n",
              "       -0.00936146, -0.00137215, -0.00160775, -0.01388822, -0.00114363,\n",
              "       -0.00562447, -0.015834  ,  0.00203665, -0.00819761,  0.00357515,\n",
              "       -0.00704474,  0.01187678,  0.01397098, -0.0003595 ,  0.01483709,\n",
              "        0.00642386,  0.00716366,  0.01733554, -0.00813913, -0.01724182,\n",
              "        0.01472687, -0.00172192,  0.0145547 ,  0.00332452,  0.01117037,\n",
              "        0.00387043,  0.01245523,  0.01104997,  0.00397252,  0.00180487,\n",
              "       -0.00106811, -0.00782063,  0.00305819, -0.00226292, -0.00710015],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WABXufuQNec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "0513bd78-e9ed-4bd8-a671-8ec7f631d417"
      },
      "source": [
        "print(generate_text(model, start_string=u\"ROMEO: \"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROMEO: how now?\n",
            "\n",
            "ISABELLA:\n",
            "Pleay earnous.\n",
            "\n",
            "MISHARD III:\n",
            "I speak to thus.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "What makes your friends Capil, and what the deputy nor anger groom.\n",
            "If He were petervast death at news\n",
            "By all guilty, or was expediate thy tongue\n",
            "And that thou keep's open, and see who case wainly a\n",
            "chows of Edward leads did like talk'd ason he:\n",
            "Is't, no more, or. what liar, I know\n",
            "What come from the house of Larcius i' the island upon the wine,\n",
            "And made your pleasure may I would be took\n",
            "Have fault? I would not dear Milan; wortht my part,\n",
            "Lest all fine and death'd to your comfort!\n",
            "\n",
            "O does?\n",
            "\n",
            "DORSET:\n",
            "I am with my daughter.\n",
            "\n",
            "LADY CAPULET:\n",
            "O, and in thy common sword I stay that while\n",
            "\n",
            "GOLZALO:\n",
            "That shall grieve you tell them, do you quiet.\n",
            "\n",
            "BUCKINGHAM:\n",
            "God as Lord Stalliabter.\n",
            "\n",
            "HORTENBIO:\n",
            "Fear conceiving that they are stull, and let the silent Clarence call you\n",
            "comes to-night;\n",
            "Sirrah Grost Florizel will take theirs. re in men,\n",
            "And in their temples in my partly sound.\n",
            "\n",
            "GRENI:\n",
            "And you dissente it in the ways.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ34Jjm1TVyC"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inp)\n",
        "        loss = tf.reduce_mean(\n",
        "            tf.keras.losses.sparse_categorical_crossentropy(\n",
        "                target, predictions, from_logits=True))\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5U88x2mDzyq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}